{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19e5d3b2-33f8-43ed-aa74-e54d951ee4ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pyspark.sql.functions as pyf\n",
    "import pyspark.sql.types as pyt\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from acosta.alerting.preprocessing.functions import get_params_from_database_name, get_hash_org_unit_num_udf\n",
    "\n",
    "from expectation.functions import pivot_pos, get_pos_prod, get_price\n",
    "from expectation.model import get_latest_file_path\n",
    "from expectation import parse_widget_or_raise\n",
    "\n",
    "is_called = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4188c918-f31b-4927-993f-8e1192fb30a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text('database_name', '', 'Database Name')\n",
    "dbutils.widgets.text('company_id', '', 'Company Id')\n",
    "dbutils.widgets.text('parent_chain_id', '', 'Parent Chain Id')\n",
    "dbutils.widgets.text('manufacturer_id', '', 'Manufacturer Id')\n",
    "dbutils.widgets.text('confidence_level', '80', 'Confidence Level')\n",
    "\n",
    "\n",
    "database_name = parse_widget_or_raise(dbutils.widgets.get('database_name'))\n",
    "required_int_inputs = (\n",
    "     'company_id', 'parent_chain_id', 'confidence_level')\n",
    "int_parsed = [int(parse_widget_or_raise(dbutils.widgets.get(key))) for key in required_int_inputs]\n",
    "company_id, parent_chain_id, confidence_level = int_parsed\n",
    "\n",
    "manufacturer_id = dbutils.widgets.get('manufacturer_id')\n",
    "manufacturer_id = int(manufacturer_id) if len(manufacturer_id) != 0 else None\n",
    "\n",
    "source, country_code, client, retailer = get_params_from_database_name(database_name).values()\n",
    "print(f'client: {client}, country_code: {country_code}, retailer: {retailer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9756fb0-bdb5-4011-9636-fb742fc8ba24",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "database_config_dict = get_params_from_database_name(database_name)\n",
    "# NOTE: we have to define these parameters for 03.0_Retail_Alert_Database_DDL notebook only - we don't use them in this notebook\n",
    "RETAILER, CLIENT, COUNTRY_CODE = [\n",
    "    database_config_dict[key]\n",
    "    for key in ['retailer', 'client', 'country_code']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c41aa01-ae38-4dd1-b681-1a79fc64dc8d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %run \"./03.0_Retail_Alert_Database_DDL\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2eba994f-aefc-4ac1-acff-c38813a58f65",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58f8ded4-aa75-44a8-b61d-8185ba483501",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "time_zone = 'Europe/London' if country_code == 'uk' else 'America/Toronto'\n",
    "local_time = pytz.timezone(time_zone)\n",
    "today_date = datetime.datetime.now(local_time).strftime('%Y-%m-%d')\n",
    "today_date = datetime.datetime.strptime(today_date, '%Y-%m-%d').date()\n",
    "\n",
    "similar_store_not_available = False\n",
    "similar_store_expired = False\n",
    "\n",
    "DatabaseName = f'retail_alert_{retailer}_{client}_{country_code}_im'\n",
    "TableName = f'{DatabaseName}.similar_stores'\n",
    "df_store_matches = spark.sql(f\"SELECT * FROM {TableName}\")\n",
    "\n",
    "if df_store_matches.count() == 0:\n",
    "    similar_store_not_available = True\n",
    "\n",
    "if similar_store_not_available:\n",
    "    dbutils.notebook.run(\n",
    "        '01_CalculateSimilarStores', 10800, {\n",
    "            'database_name': database_name,\n",
    "            'company_id': company_id,\n",
    "            'parent_chain_id': parent_chain_id,\n",
    "            'manufacturer_id': dbutils.widgets.get('manufacturer_id')\n",
    "        })\n",
    "\n",
    "max_load_ts = df_store_matches.agg(pyf.max('LOAD_TS').alias('max_load_ts')).collect()[0]['max_load_ts']\n",
    "latest_date = max_load_ts.date()\n",
    "print('The latest date of matched stores', latest_date)\n",
    "if latest_date < (today_date - datetime.timedelta(days=30)):\n",
    "    similar_store_expired = True\n",
    "df_store_matches = df_store_matches.filter(pyf.col('LOAD_TS') == max_load_ts).drop('LOAD_TS')\n",
    "print(f'N of similar stores = {df_store_matches.cache().count():,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccf7d727-9f6e-4296-9573-1e6361db7c32",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_full_pos = get_pos_prod(\n",
    "    database_name,\n",
    "    spark,\n",
    "    n_days=90,\n",
    "    method='Gen2_DLA'\n",
    ")\n",
    "print(df_full_pos.select(pyf.max('SALES_DT')).collect()[0][0])\n",
    "df_full_pos = df_full_pos.filter(pyf.col('SALES_DT') < today_date)\n",
    "print(df_full_pos.select(pyf.max('SALES_DT')).collect()[0][0])\n",
    "\n",
    "# update POS_ITEM_QTY based on 0 inventory\n",
    "df_full_pos = df_full_pos.withColumnRenamed('POS_ITEM_QTY', 'POS_ITEM_QTY_ORG')\n",
    "df_full_pos = df_full_pos.withColumn(\n",
    "    'POS_INV',\n",
    "    pyf.when(\n",
    "        ((df_full_pos['ON_HAND_INVENTORY_QTY'] == 0)\\\n",
    "        & (df_full_pos['POS_ITEM_QTY_ORG'] == 0)), -1\n",
    "    ).otherwise(df_full_pos['POS_ITEM_QTY_ORG'])\n",
    ").withColumnRenamed('POS_INV', 'POS_ITEM_QTY')\n",
    "\n",
    "print(f'N = {df_full_pos.cache().count():,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0af182c-76cd-4d7a-837b-f33ea8d289a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "max_date = df_full_pos.select(pyf.max('SALES_DT')).collect()[0][0]\n",
    "print(max_date)\n",
    "print(df_full_pos.filter(pyf.col('SALES_DT') == max_date).count())\n",
    "print(df_full_pos.filter(pyf.col('SALES_DT') == max_date).filter(pyf.col('POS_ITEM_QTY_ORG') != 0).count())\n",
    "print(df_full_pos.filter(pyf.col('SALES_DT') == max_date).filter(pyf.col('ON_HAND_INVENTORY_QTY') != 0).count())\n",
    "print(df_full_pos.filter(pyf.col('SALES_DT') == max_date).filter(pyf.col('POS_ITEM_QTY') != -1).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3993fe8-6d62-4b47-9c6e-360677d1f051",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "max_date = '2024-07-08'\n",
    "print(df_full_pos.filter(pyf.col('SALES_DT') == max_date).count())\n",
    "print(df_full_pos.filter(pyf.col('SALES_DT') == max_date).filter(pyf.col('POS_ITEM_QTY_ORG') != 0).count())\n",
    "print(df_full_pos.filter(pyf.col('SALES_DT') == max_date).filter(pyf.col('ON_HAND_INVENTORY_QTY') != 0).count())\n",
    "print(df_full_pos.filter(pyf.col('SALES_DT') == max_date).filter(pyf.col('POS_ITEM_QTY') != -1).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f36d974f-6f41-4354-8cdc-61627e551def",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#join POS data and similar stores\n",
    "df_pivot = pivot_pos(\n",
    "    df_full_pos,\n",
    "    'daily',\n",
    "    2\n",
    ")\n",
    "\n",
    "df_pos = df_store_matches.join(\n",
    "    df_pivot,\n",
    "    (df_store_matches['ORGANIZATION_UNIT_NUM'] == df_pivot['ORGANIZATION_UNIT_NUM'])\n",
    "     & (df_store_matches['RETAILER_ITEM_ID']== df_pivot['RETAILER_ITEM_ID']),\n",
    "    how='left'\n",
    ").drop(df_pivot['RETAILER_ITEM_ID'])\\\n",
    ".drop(df_pivot['ORGANIZATION_UNIT_NUM'])\n",
    "\n",
    "print(f'N = {df_pos.cache().count():,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32bf50e1-e835-42a5-b926-94734c31e31a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter out combinations that will cause index errors\n",
    "def create_assertion_message(dfi):\n",
    "    assertion_message = f'Item = {dfi[\"RETAILER_ITEM_ID\"].unique()[0]} & TestStore = {dfi[\"TEST_ORGANIZATION_UNIT_NUM\"].unique()[0]}'\n",
    "    return assertion_message\n",
    "\n",
    "\n",
    "def label_data_as_safe_udf(dfi):\n",
    "    assertion_message = create_assertion_message(dfi)\n",
    "    assert dfi['RETAILER_ITEM_ID'].nunique() == 1, 'Check GroupBy code: ' + assertion_message\n",
    "    assert dfi['TEST_ORGANIZATION_UNIT_NUM'].nunique() == 1, 'Check data preprocessing process: ' + assertion_message\n",
    "\n",
    "    test_store_num = dfi['TEST_ORGANIZATION_UNIT_NUM'].unique()[0]\n",
    "    n_stores = dfi['ORGANIZATION_UNIT_NUM'].nunique()\n",
    "\n",
    "    n_store_cond_passed = n_stores > 1\n",
    "    test_store_is_present = test_store_num in set(dfi['ORGANIZATION_UNIT_NUM'].values)\n",
    "    is_safe_test_store = n_store_cond_passed and test_store_is_present\n",
    "\n",
    "    # Process data\n",
    "    cols_to_drop = ['RETAILER_ITEM_ID', 'TEST_ORGANIZATION_UNIT_NUM', 'DISTANCE',\n",
    "                    'CAP_VALUE', 'MAX_ALERTS_PER_STORE']\n",
    "    data = dfi.drop(columns=cols_to_drop)\n",
    "    data = data.sort_values(by='ORGANIZATION_UNIT_NUM')\n",
    "    data = data.dropna(axis='columns', how='all')\n",
    "    data = data.fillna(0)\n",
    "    data.index = data['ORGANIZATION_UNIT_NUM']\n",
    "\n",
    "    # Check if is safe\n",
    "    is_safe_data = True\n",
    "    try:\n",
    "        _ = data.drop(columns='ORGANIZATION_UNIT_NUM', index=test_store_num).values.T\n",
    "        _ = data.drop(columns='ORGANIZATION_UNIT_NUM').loc[test_store_num].values\n",
    "        _ = _[-1]\n",
    "    except:\n",
    "        is_safe_data = False\n",
    "\n",
    "    dfi['is_safe'] = is_safe_data and is_safe_test_store\n",
    "    return dfi\n",
    "\n",
    "\n",
    "label_data_as_safe_schema = pyt.StructType(\n",
    "    list(df_pos.schema) +\n",
    "    [pyt.StructField('is_safe', pyt.BooleanType())]\n",
    ")\n",
    "\n",
    "df_pos = df_pos\\\n",
    "    .groupby('RETAILER_ITEM_ID', 'TEST_ORGANIZATION_UNIT_NUM')\\\n",
    "    .applyInPandas(label_data_as_safe_udf, schema=label_data_as_safe_schema)\n",
    "print(f'N_1 = {df_pos.cache().count():,}')\n",
    "\n",
    "df_pos = df_pos.filter('is_safe is True')\n",
    "df_pos = df_pos.drop('is_safe')\n",
    "print(f'N_f = {df_pos.cache().count():,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "215c9a97-d117-436c-a7e4-787ee38993bb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Estimate Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f3ff28f-bce6-4de8-b704-1c9b903f827e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def poisson_geometric_expectation(obs, rate: float, n_zero_days: int):\n",
    "    prob_zero_sales = stats.poisson(rate).pmf(0)\n",
    "    prob_nonzero_sales = 1 - prob_zero_sales\n",
    "\n",
    "    # Only the poisson distribution is required to compute the probability of non-zero sales\n",
    "    prob_given_nonzero = stats.poisson(rate).cdf(obs)\n",
    "    # Both the poisson and the geometric distribution is required to compute the probability of observed sales\n",
    "    prob_given_zero = stats.geom(p=prob_nonzero_sales).sf(n_zero_days)\n",
    "\n",
    "    if isinstance(obs, np.ndarray):\n",
    "        selector = obs > 0\n",
    "        prob = prob_given_zero.copy()\n",
    "        prob[selector] = prob_given_nonzero[selector]\n",
    "    else:\n",
    "        prob = prob_given_nonzero if obs > 0 else prob_given_zero\n",
    "    return prob\n",
    "\n",
    "\n",
    "def count_trailing_zeros(array: np.ndarray):\n",
    "    reversed_array = array[::-1]\n",
    "    n = np.argmax(reversed_array != 0)\n",
    "    if n == 0 and np.all(reversed_array == 0):\n",
    "        n = len(reversed_array)\n",
    "    return n\n",
    "\n",
    "\n",
    "def compute_lost_sales(obs, rate:float):\n",
    "    if isinstance(obs, np.ndarray):\n",
    "        selector = obs > 0\n",
    "        lost_sales = np.zeros_like(obs)\n",
    "        lost_sales[selector] = (rate - obs)[selector]\n",
    "        lost_sales[~selector] = rate[~selector]\n",
    "    else:\n",
    "        lost_sales = rate - obs if obs > 0 else rate\n",
    "    return np.maximum(lost_sales, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5702dd2-c640-4364-88a8-81b73538fa18",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fit_udf_schema = pyt.StructType([\n",
    "    pyt.StructField('RETAILER_ITEM_ID', pyt.StringType()),\n",
    "    pyt.StructField('TEST_ORGANIZATION_UNIT_NUM', pyt.StringType()),\n",
    "    pyt.StructField('DATE', pyt.DateType()),\n",
    "    pyt.StructField('LAST_OBS', pyt.FloatType()),\n",
    "    pyt.StructField('LAST_RATE', pyt.FloatType()),\n",
    "    pyt.StructField('LAST_LOST_SALES', pyt.FloatType()),\n",
    "    pyt.StructField('N_DAYS_LAST_SALE', pyt.IntegerType()),\n",
    "    pyt.StructField('PROB', pyt.FloatType()),\n",
    "    pyt.StructField('ZSCORE', pyt.FloatType()),\n",
    "    pyt.StructField('R2', pyt.FloatType()),\n",
    "    pyt.StructField('RMSE', pyt.FloatType()),\n",
    "    pyt.StructField('CAP_VALUE', pyt.DecimalType(6,2)),\n",
    "    pyt.StructField('MAX_ALERTS_PER_STORE', pyt.IntegerType())\n",
    "])\n",
    "fit_udf_cols = [col.name for col in fit_udf_schema]\n",
    "\n",
    "\n",
    "def fit_udf(dfi):\n",
    "    assertion_message = create_assertion_message(dfi)\n",
    "    assert dfi['RETAILER_ITEM_ID'].nunique() == 1, 'Check groupby code' + assertion_message\n",
    "    assert dfi['TEST_ORGANIZATION_UNIT_NUM'].nunique() == 1, 'Check data preprocessing process' + assertion_message\n",
    "    test_store_num = dfi['TEST_ORGANIZATION_UNIT_NUM'].unique()[0]\n",
    "\n",
    "    dfi = dfi.drop_duplicates(['RETAILER_ITEM_ID', 'TEST_ORGANIZATION_UNIT_NUM', 'ORGANIZATION_UNIT_NUM'])\n",
    "    cols_to_drop = ['RETAILER_ITEM_ID', 'TEST_ORGANIZATION_UNIT_NUM',\n",
    "                    'DISTANCE', 'CAP_VALUE', 'MAX_ALERTS_PER_STORE'\n",
    "                   ]\n",
    "    data = dfi.drop(columns=cols_to_drop)\n",
    "    data = data.sort_values(by='ORGANIZATION_UNIT_NUM')\n",
    "    data = data.dropna(axis='columns', how='all')\n",
    "    data = data.fillna(0)\n",
    "    data.index = data['ORGANIZATION_UNIT_NUM']\n",
    "\n",
    "    x = data.drop(columns='ORGANIZATION_UNIT_NUM', index=test_store_num).values.T\n",
    "    y = data.drop(columns='ORGANIZATION_UNIT_NUM').loc[test_store_num].values\n",
    "\n",
    "    dates = pd.to_datetime(data.drop(columns='ORGANIZATION_UNIT_NUM').columns)\n",
    "\n",
    "    last_obs = y[-1]\n",
    "    n_days_since_last_sale = None\n",
    "    last_rate = None\n",
    "    prob = None\n",
    "    last_lost_sales = None\n",
    "    z_score = None\n",
    "    r2 = None\n",
    "    rmse = None\n",
    "\n",
    "    # Fit Models\n",
    "    try:\n",
    "        clf = GradientBoostingRegressor(random_state=1, n_iter_no_change=3, validation_fraction=0.1)\n",
    "        clf.fit(x[:-1], y[:-1])\n",
    "        last_rate = clf.predict(x[-1:])[0]\n",
    "        n_days_since_last_sale = count_trailing_zeros(y.flatten())\n",
    "\n",
    "        # Compute probabilities\n",
    "        if last_rate < 0:\n",
    "            last_rate = 0.0005\n",
    "        prob = poisson_geometric_expectation(\n",
    "            obs=last_obs,\n",
    "            rate=last_rate,\n",
    "            n_zero_days=n_days_since_last_sale\n",
    "        )\n",
    "        z_score = -stats.norm().ppf(prob)  # Larger represent more extreme observations\n",
    "\n",
    "        # Compute lost items\n",
    "        last_lost_sales = compute_lost_sales(\n",
    "            obs=last_obs,\n",
    "            rate=last_rate,\n",
    "        )\n",
    "\n",
    "        # Metrics\n",
    "        r2 = r2_score(y[:-1], clf.predict(x[:-1]))\n",
    "        rmse = np.sqrt(mean_squared_error(y[:-1], clf.predict(x[:-1])))\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f'=== ERROR OCCURRED fitting {assertion_message} ===')\n",
    "        print(e)\n",
    "        traceback.print_exc()\n",
    "\n",
    "    # Generate results\n",
    "    df_results = dfi[['RETAILER_ITEM_ID', 'TEST_ORGANIZATION_UNIT_NUM']].drop_duplicates().astype(str)\n",
    "    df_results['DATE'] = dates[-1]\n",
    "    df_results['R2'] = r2\n",
    "    df_results['RMSE'] = rmse\n",
    "    df_results['LAST_OBS'] = last_obs\n",
    "    df_results['LAST_RATE'] = last_rate\n",
    "    df_results['LAST_LOST_SALES'] = last_lost_sales\n",
    "    df_results['N_DAYS_LAST_SALE'] = n_days_since_last_sale\n",
    "    df_results['PROB'] = prob\n",
    "    df_results['ZSCORE'] = z_score\n",
    "    df_results['CAP_VALUE'] = dfi['CAP_VALUE'].unique()[0]\n",
    "    df_results['MAX_ALERTS_PER_STORE'] = dfi['MAX_ALERTS_PER_STORE'].unique()[0]\n",
    "\n",
    "    return df_results[fit_udf_cols]\n",
    "\n",
    "df_prepared = df_pos.groupby('RETAILER_ITEM_ID', 'TEST_ORGANIZATION_UNIT_NUM').applyInPandas(fit_udf, schema=fit_udf_schema)\n",
    "print(f'N = {df_prepared.cache().count():,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dee2fd2-1294-40da-b808-2bc3e6ab9d7c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_prepared = df_prepared\\\n",
    "    .filter(pyf.col('LAST_LOST_SALES') > 0)\\\n",
    "    .filter(pyf.col('Date') >= pyf.date_sub(pyf.from_utc_timestamp(pyf.current_timestamp(), time_zone), 3))\n",
    "print(f'N after filtering Date and lost sales\\n -> {df_prepared.cache().count():,}')\n",
    "\n",
    "if df_prepared.count() == 0:\n",
    "    raise ValueError('There is no LSV > 0 or there is no up to date sales record')\n",
    "\n",
    "df_price = get_price(database_name, spark)\n",
    "\n",
    "df_prepared = df_prepared.join(\n",
    "    df_full_pos.selectExpr(\n",
    "        'RETAILER_ITEM_ID',\n",
    "        'ORGANIZATION_UNIT_NUM AS TEST_ORGANIZATION_UNIT_NUM',\n",
    "        'SALES_DT AS DATE',\n",
    "        'ON_HAND_INVENTORY_QTY',\n",
    "    ),\n",
    "    ['RETAILER_ITEM_ID', 'TEST_ORGANIZATION_UNIT_NUM', 'DATE'],\n",
    "    how='inner'\n",
    ").drop(df_full_pos['ORGANIZATION_UNIT_NUM'])\n",
    "\n",
    "df_prepared = df_prepared\\\n",
    "     .join(df_price.selectExpr(\n",
    "        'RETAILER_ITEM_ID',\n",
    "        'ORGANIZATION_UNIT_NUM AS TEST_ORGANIZATION_UNIT_NUM',\n",
    "        'SALES_DT AS DATE',\n",
    "        'PRICE',\n",
    "    ),\n",
    "         on=['RETAILER_ITEM_ID', 'TEST_ORGANIZATION_UNIT_NUM', 'DATE'])\n",
    "\n",
    "\n",
    "df_prepared = df_prepared.withColumn(\n",
    "    'LostSalesValue',\n",
    "    df_prepared['LAST_LOST_SALES'] * df_prepared['PRICE']\n",
    ")\n",
    "\n",
    "df_prepared = df_prepared.withColumn(\n",
    "    'LostSalesValue',\n",
    "    pyf.when(\n",
    "        pyf.col('LostSalesValue').isNotNull(),\n",
    "        pyf.col('LostSalesValue')\n",
    "    ).otherwise(pyf.lit(0.0))\n",
    ")\n",
    "print(f'N = {df_prepared.cache().count():,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc2f0e5f-c91d-4543-8b46-d10fe60d4792",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d61307d-188f-494e-adfb-5d803e49b477",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_prepared.filter(pyf.col('PROB') <= 1-80/100).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39a5c30f-59dc-40f4-b5d7-deaa0cbfece9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_prepared.filter(pyf.col('PROB') <= 1-70/100).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af3a3fec-2eed-4a58-9d6e-5ad0aa567376",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_prepared.filter(pyf.col('PROB') <= 1-60/100).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ced661d-43d8-4c8a-9ca6-12b4a00e70e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_prepared.filter(pyf.col('PROB') <= 1-50/100).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a00885d6-bdb1-4410-aff2-c1b98391ac41",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## end of test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "956ca054-36f0-4e0f-852c-4e8bb703f159",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Generate Final Alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7eb9652-2657-4db6-ae6c-c5089dbb3187",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_prepared = df_prepared.filter(pyf.col('PROB') <= 1-confidence_level/100)\n",
    "print(f'N after confidence threshold = {df_prepared.cache().count():,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5aa707d-220f-4fbf-94e6-4b197df8e776",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "maximum_num_alerts = float(\n",
    "    df_prepared.select('MAX_ALERTS_PER_STORE').collect()[0][0]\n",
    ")\n",
    "maximum_num_alerts = max(maximum_num_alerts, 1.00) #NOTE: added this to ensure df is not null in the cases that we don't want any OSA alerts\n",
    "\n",
    "def filter_alerts_by_confidence(df, confidence_level_list):\n",
    "    for c in confidence_level_list:\n",
    "        df = df.withColumn(\n",
    "            f'CONFIDENCE_{int(c*100)}',\n",
    "            pyf.when(\n",
    "                pyf.col('PROB') <= (1 - c),\n",
    "                pyf.lit(c)\n",
    "            ).otherwise(pyf.lit(None).cast(pyt.FloatType()))\n",
    "        )\n",
    "    cols = [pyf.col(c) for c in df.columns if c.startswith('CONFIDENCE')]\n",
    "    df = df.withColumn('CONFIDENCE', pyf.coalesce(*cols))\n",
    "\n",
    "    win_spec = Window.partitionBy(\n",
    "        'TEST_ORGANIZATION_UNIT_NUM',\n",
    "        'CONFIDENCE'\n",
    "    ).orderBy(pyf.col('LostSalesValue').desc())\n",
    "\n",
    "    df = df.withColumn(\n",
    "        'lsv_rank',\n",
    "        pyf.row_number().over(win_spec)\n",
    "    )\n",
    "    win_spec = Window.partitionBy(\n",
    "        'TEST_ORGANIZATION_UNIT_NUM'\n",
    "    )\\\n",
    "        .orderBy(pyf.col('lsv_rank'))\\\n",
    "        .orderBy(pyf.col('CONFIDENCE').desc())\n",
    "\n",
    "    df = df.withColumn(\n",
    "        'row_number',\n",
    "        pyf.row_number().over(win_spec)\n",
    "    ).drop(*[c for c in df.columns if c.startswith('CONFIDENCE')])\n",
    "\n",
    "    df = df\\\n",
    "    .filter(\n",
    "        df['row_number'] <= maximum_num_alerts)\\\n",
    "    .drop('row_number', 'lsv_rank')\n",
    "    return df\n",
    "\n",
    "\n",
    "confidence_level_list = [0.95, 0.9, 0.85, 0.75, 0.5, 0]\n",
    "df_final = filter_alerts_by_confidence(\n",
    "    df_prepared, confidence_level_list\n",
    ")\n",
    "df_final = df_final.withColumnRenamed('TEST_ORGANIZATION_UNIT_NUM', 'ORGANIZATION_UNIT_NUM')\n",
    "print(f'N = {df_final.cache().count():,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a42c85ba-c6b3-4a8f-b3d5-4ffc01be786d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def performance_summary(df_prepared, df_alerts):\n",
    "    print('Summary of df_prepared:')\n",
    "    display(df_prepared.describe())\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(15,5))\n",
    "\n",
    "    sns.histplot(df_prepared.select('R2').toPandas()['R2'], kde=True, ax=axs[0])\n",
    "    sns.histplot(df_prepared.select('RMSE').toPandas()['RMSE'], kde=True, ax=axs[1])\n",
    "    sns.histplot(df_prepared.select('PROB').toPandas()['PROB'], kde=True, ax=axs[2])\n",
    "    sns.histplot(df_alerts.select('LostSalesValue').toPandas()['LostSalesValue'], kde=True, ax=axs[3])\n",
    "\n",
    "    fig.suptitle('Model Performance on Training Data')\n",
    "    plt.axvline(0)\n",
    "    display(plt.show())\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"mean R2: {df_prepared.select('R2').toPandas()['R2'].mean():.2f}, mean RMSE: {df_prepared.select('RMSE').toPandas()['RMSE'].mean():.2f}\")\n",
    "\n",
    "    print('\\n Summary of final alerts')\n",
    "    display(df_alerts.describe())\n",
    "\n",
    "    unique_stores = df_alerts.select(pyf.countDistinct('ORGANIZATION_UNIT_NUM')).collect()[0][0]\n",
    "    unique_products = df_alerts.select(pyf.countDistinct('RETAILER_ITEM_ID')).collect()[0][0]\n",
    "    print('\\n Min and max number of alerts per ORGANIZATION_UNIT_NUM')\n",
    "    display(df_alerts.groupBy('ORGANIZATION_UNIT_NUM').count().select(pyf.max('count'), pyf.min('count')))\n",
    "\n",
    "    print(f'Total Alerts = {df_alerts.count():,} \\n Number of unique Stores = {unique_stores} \\n Number of unique products = {unique_products}')\n",
    "\n",
    "performance_summary(df_prepared, df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13ee7d16-085f-4162-9225-9c46210358e6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Gen2 Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1946cb6c-ede3-4207-aa00-f49c715150d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "unique_org_item = df_full_pos.select('ORGANIZATION_UNIT_NUM', 'RETAILER_ITEM_ID').distinct()\n",
    "df_final = df_final.withColumn('LSV', pyf.col('LostSalesValue') + pyf.col('CAP_VALUE'))\n",
    "df_final = df_final.withColumn('FORECAST', pyf.col('LSV') / pyf.col('PRICE') + pyf.col('LAST_OBS'))\n",
    "\n",
    "# join unique_org_item with df_final and ensure date is correct and forecast is zero\n",
    "last_date = df_final.agg({'DATE': 'min'}).collect()[0][0]\n",
    "df_final = unique_org_item.join(df_final,\n",
    "                                    on=['ORGANIZATION_UNIT_NUM', 'RETAILER_ITEM_ID'],\n",
    "                                    how='left')\\\n",
    "                              .fillna({'FORECAST': 0})\\\n",
    "                              .withColumn('DATE', pyf.lit(last_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45d5b476-9928-467a-bb22-f4a7d3125d32",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fit_forecast_schema = pyt.StructType([\n",
    "    pyt.StructField('RETAILER_ITEM_ID', pyt.StringType()),\n",
    "    pyt.StructField('ORGANIZATION_UNIT_NUM', pyt.StringType()),\n",
    "    pyt.StructField('DATE', pyt.DateType()),\n",
    "    pyt.StructField('FORECAST', pyt.FloatType()),\n",
    "])\n",
    "fit_forecast_cols = [col.name for col in fit_forecast_schema]\n",
    "\n",
    "def fit_forecast(dfi):\n",
    "    dfi.index = pd.to_datetime(dfi['DATE'])\n",
    "    d = dfi.index.min()\n",
    "    forecast = dfi.FORECAST.values[0]\n",
    "    ix = pd.date_range(\n",
    "        start=d - datetime.timedelta(7),\n",
    "        end=d + datetime.timedelta(7),\n",
    "        freq='D'\n",
    "    )\n",
    "    dfi = dfi.reindex(ix)\n",
    "    dfi.loc[:,['ORGANIZATION_UNIT_NUM', 'RETAILER_ITEM_ID']] = dfi.loc[:,['ORGANIZATION_UNIT_NUM', 'RETAILER_ITEM_ID']].ffill().bfill()\n",
    "    dfi['DATE'] = dfi.index\n",
    "    if forecast != 0:\n",
    "        dfi.loc[dfi.index < d, 'FORECAST'] = 0\n",
    "        dfi.loc[dfi.index >= d, 'FORECAST'] = dfi.loc[dfi.index >= d, 'FORECAST'].ffill()\n",
    "    else:\n",
    "        dfi.loc[:, 'FORECAST'] = 0\n",
    "\n",
    "    return dfi[fit_forecast_cols]\n",
    "\n",
    "df_predictions = df_final.select('RETAILER_ITEM_ID', 'ORGANIZATION_UNIT_NUM', 'DATE', 'FORECAST')\\\n",
    "        .groupby('RETAILER_ITEM_ID', 'ORGANIZATION_UNIT_NUM')\\\n",
    "        .applyInPandas(fit_forecast, schema=fit_forecast_schema)\n",
    "\n",
    "spark.sparkContext.setCheckpointDir(f'/mnt/processed/gen2_dla/checkpoints/{retailer}_{client}_{country_code}/')\n",
    "df_predictions = df_predictions.checkpoint()\n",
    "print(f'N = {df_predictions.cache().count():,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85c98e90-a962-4607-a57e-83aa17c36057",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Write Final Alerts into Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9b55ba5-b7b9-4d37-a347-0c63bee4bea4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# rename columns and add additional metadata to the predictions\n",
    "prediction_results_dataframe = df_predictions.selectExpr(\n",
    "    'ORGANIZATION_UNIT_NUM',\n",
    "    'RETAILER_ITEM_ID',\n",
    "    'CURRENT_TIMESTAMP() as LOAD_TS',\n",
    "    '\"Dynamic.Retail.Engine.Gen2\" as RECORD_SOURCE_CD',\n",
    "    'FORECAST as BASELINE_POS_ITEM_QTY',\n",
    "    'DATE as SALES_DT',\n",
    "    '\"GEN2-DLA\" as MODEL_ID'\n",
    ")\n",
    "\n",
    "if source is not None:\n",
    "    itemMasterTableName = f'{database_name}.vw_latest_sat_retailer_item'\n",
    "    storeMasterTableName = f'{database_name}.vw_latest_sat_organization_unit'\n",
    "\n",
    "elif source is None:\n",
    "    itemMasterTableName = f'{database_name}.hub_retailer_item'\n",
    "    storeMasterTableName = f'{database_name}.hub_organization_unit'\n",
    "\n",
    "else:\n",
    "    raise ValueError('Store and item master tables do not exist')\n",
    "\n",
    "store_master_table = spark.read.table(storeMasterTableName)\n",
    "store_master_table = store_master_table.alias('OUH')\n",
    "\n",
    "prediction_results_dataframe = prediction_results_dataframe.alias('PRDF') \\\n",
    "    .join(store_master_table,\n",
    "          pyf.col('OUH.ORGANIZATION_UNIT_NUM') == pyf.col('PRDF.ORGANIZATION_UNIT_NUM'), 'inner') \\\n",
    "    .join(sqlContext.read.table(itemMasterTableName).alias('RIH'),\n",
    "          pyf.col('RIH.RETAILER_ITEM_ID') == pyf.col('PRDF.RETAILER_ITEM_ID'), 'inner') \\\n",
    "    .select('PRDF.*', 'OUH.HUB_ORGANIZATION_UNIT_HK', 'RIH.HUB_RETAILER_ITEM_HK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bc8b8a1-27c4-46ef-9b2f-fb682099a332",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f'Confirm non-zero count {prediction_results_dataframe.cache().count():,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e597b0e-43e6-441b-b940-63c6e306047f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# insertDatabaseName = f'retail_alert_{retailer}_{client}_{country_code}_im'\n",
    "# insertTableName = f'{insertDatabaseName}.DRFE_FORECAST_BASELINE_UNIT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff6324d9-655a-45f5-b5cc-4fab276e7dae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# try:\n",
    "#     prediction_results_dataframe\\\n",
    "#         .select('HUB_ORGANIZATION_UNIT_HK', 'HUB_RETAILER_ITEM_HK', 'LOAD_TS', 'RECORD_SOURCE_CD', 'BASELINE_POS_ITEM_QTY',\n",
    "#                 'MODEL_ID', 'SALES_DT')\\\n",
    "#         .write.mode('overwrite').insertInto(insertTableName, overwrite=True)\n",
    "# except:\n",
    "#     selected_data = prediction_results_dataframe.select(\n",
    "#         'HUB_ORGANIZATION_UNIT_HK', 'HUB_RETAILER_ITEM_HK', 'LOAD_TS',\n",
    "#         'RECORD_SOURCE_CD', 'BASELINE_POS_ITEM_QTY', 'MODEL_ID', 'SALES_DT')\n",
    "#     selected_data.write.mode('overwrite').saveAsTable(\"temp_table\")\n",
    "#     spark.sql(f\"INSERT INTO {insertTableName} SELECT * FROM temp_table\")\n",
    "#     print('used modified version')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0585d05-eff8-4285-a9c6-019e0b441b6b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# if similar_store_expired:\n",
    "#     dbutils.notebook.run(\n",
    "#         '01_CalculateSimilarStores', 10800, {\n",
    "#             'database_name': database_name,\n",
    "#             'company_id': company_id,\n",
    "#             'parent_chain_id': parent_chain_id,\n",
    "#             'manufacturer_id': dbutils.widgets.get('manufacturer_id')\n",
    "#         })"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Test Number of Candidate Gen2_DLA Alerts by Confidence Interval (2024-07-10)",
   "widgets": {
    "company_id": {
     "currentValue": "567",
     "nuid": "c2c7478c-3503-40b9-a1cb-037509d75fc9",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Company Id",
      "name": "company_id",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "confidence_level": {
     "currentValue": "80",
     "nuid": "f7a954c3-8890-481f-bb8d-4b5d1ca36870",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "80",
      "label": "Confidence Level",
      "name": "confidence_level",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "database_name": {
     "currentValue": "retaillink_walmart_danoneusllc_us_dv",
     "nuid": "95645433-4fc0-40b1-a856-0a9ae3c8573e",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Database Name",
      "name": "database_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "manufacturer_id": {
     "currentValue": "235",
     "nuid": "1abfb59b-ea3e-49b4-ab9b-1724e893b65c",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Manufacturer Id",
      "name": "manufacturer_id",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "parent_chain_id": {
     "currentValue": "950",
     "nuid": "49a78eeb-e2ab-449f-a96a-0777ded392dd",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Parent Chain Id",
      "name": "parent_chain_id",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
